{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0f56cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd67f94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "351a30f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mish(x):\n",
    "    return x * tf.math.tanh(tf.math.softplus(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5469edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self,dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.conv1 = tf.keras.layers.Conv2D(dim//4,1,activation=mish)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(dim//4,3,activation=mish,padding='same')\n",
    "        self.conv3 = tf.keras.layers.Conv2D(dim,1)\n",
    "        \n",
    "    def build(self,inp_shape):\n",
    "        if inp_shape[-1] != self.dim:\n",
    "            self.transfer = tf.keras.layers.Conv2D(self.dim,1)\n",
    "            self.need_transfer = True\n",
    "        else:\n",
    "            self.need_transfer = False\n",
    "        \n",
    "    def call(self,inp):\n",
    "        x = self.conv1(inp)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        if self.need_transfer:\n",
    "            inp = self.transfer(inp)\n",
    "        x = x + inp\n",
    "        x = mish(x)\n",
    "        return x\n",
    "    \n",
    "class Block(tf.keras.layers.Layer):\n",
    "    def __init__(self,dim,subblocks):\n",
    "        super().__init__()\n",
    "        self.subblocks = [SubBlock(dim) for _ in range(subblocks)]\n",
    "        self.maxpooling = tf.keras.layers.MaxPooling2D(2,2)\n",
    "    def call(self,x):\n",
    "        for s in self.subblocks:\n",
    "            x = s(x)\n",
    "        x = self.maxpooling(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffdb8a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    Block(8,3), #16\n",
    "    Block(16,3), #8\n",
    "    Block(32,3), #4\n",
    "    Block(64,3), #2\n",
    "    Block(128,3), #1\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64,activation=mish),\n",
    "    tf.keras.layers.Dense(32,activation=mish),\n",
    "    tf.keras.layers.Dense(16,activation=mish),\n",
    "    tf.keras.layers.Dense(10),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f349bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "             metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7a190e1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3125/3125 [==============================] - 224s 70ms/step - loss: 1.8963 - sparse_categorical_accuracy: 0.3003 - val_loss: 1.7403 - val_sparse_categorical_accuracy: 0.3749\n",
      "Epoch 2/10\n",
      "3125/3125 [==============================] - 220s 70ms/step - loss: 1.5316 - sparse_categorical_accuracy: 0.4437 - val_loss: 1.4430 - val_sparse_categorical_accuracy: 0.4767\n",
      "Epoch 3/10\n",
      "3125/3125 [==============================] - 222s 71ms/step - loss: 1.3790 - sparse_categorical_accuracy: 0.5044 - val_loss: 1.3089 - val_sparse_categorical_accuracy: 0.5245\n",
      "Epoch 4/10\n",
      "3125/3125 [==============================] - 236s 76ms/step - loss: 1.2829 - sparse_categorical_accuracy: 0.5399 - val_loss: 1.3307 - val_sparse_categorical_accuracy: 0.5349\n",
      "Epoch 5/10\n",
      "3125/3125 [==============================] - 239s 76ms/step - loss: 1.2114 - sparse_categorical_accuracy: 0.5659 - val_loss: 1.2473 - val_sparse_categorical_accuracy: 0.5554\n",
      "Epoch 6/10\n",
      "3125/3125 [==============================] - 238s 76ms/step - loss: 1.1493 - sparse_categorical_accuracy: 0.5922 - val_loss: 1.1717 - val_sparse_categorical_accuracy: 0.5885\n",
      "Epoch 7/10\n",
      "3125/3125 [==============================] - 229s 73ms/step - loss: 1.0981 - sparse_categorical_accuracy: 0.6098 - val_loss: 1.1832 - val_sparse_categorical_accuracy: 0.5821\n",
      "Epoch 8/10\n",
      "3125/3125 [==============================] - 219s 70ms/step - loss: 1.0536 - sparse_categorical_accuracy: 0.6274 - val_loss: 1.1525 - val_sparse_categorical_accuracy: 0.60060255 - sparse_categorical_accu - ETA: 2:47 - loss: 1.0279 - sparse_categorical_accuracy:  - ETA: 2:47 - loss: 1.0291 - sparse_categorical_a - ETA: 2:46 - loss: 1.0302 - sparse_categorical_ - ETA: 2:45 - loss: 1. - ETA: 2:38 - loss: 1.0298 - sparse_c - ETA: 2:36 - loss: 1.0291 - sparse_categ - ETA: 2 - ETA: 2:22  - ETA: 2:19 - loss: 1.0326 - spa - E - ETA: 2:13 - loss: 1.0348 - sparse_categorical_accurac - ETA: 2:12 - loss: 1.0347 - sparse_categori - ETA: 2:11 - loss: 1.0361 - sparse_categorical - ETA: 2:09 - loss: 1.0355 - sparse_categorical_accuracy: 0.63 - ETA: 2:09 - loss: 1.0355 - sparse_categorical_accuracy: 0.634 - ETA: 2:09 - loss: 1.0351 - sparse_categorical_ - ETA: 2:08 - loss: 1.0365 - sparse_categorical_ac - ETA: 2:07 - loss: 1.0372 - sparse_catego - ETA: 2:01 - loss: 1.0378 - ETA: 1:58 - loss: 1.0394 - sparse_categorical_accuracy: - ETA: 1:58 - loss: 1.0390 - sparse_categorical_accuracy: 0.63 - ETA: 1:58 - loss: 1.0388 - sparse_categoric - ETA: 1:57 - loss: 1.0385 - sparse_categorical_ac - ETA: 1:56 - loss: 1.0392 - sparse_categorical_acc - ETA: 1:55 - loss: 1.0388 - sparse_cat - ETA: 1:53 - loss: 1.0373 - sparse_categorical_accuracy - ETA: 1:53 - loss: 1.0365 - sparse_categori - ETA: 1:51 - loss: 1.0364 - sparse_categorica - ETA: 1:50 - loss: 1.0357 - sparse_categorical_accuracy: 0.633 - ETA: 1:50 - loss: 1.0355 - sparse_categorical_accuracy: 0 - ETA: 1:50 - loss: 1.0354 - sparse_categorica - ETA: 1:49 - loss: 1.0349 - sparse_categ - ETA: 1:47 - loss: 1.0338 - sparse_categorical_accura - ETA: 1:47 - loss: 1.0338 - sparse_categorical_accuracy - ETA: 1:46 - loss: 1.0331 - sparse_categorical_accuracy: 0.63 - ETA: 1:46 - loss: 1.0333 - sparse_categorical_accuracy: - ETA: 1:45 - loss: 1.0337 - sparse_categorical_accuracy: 0.634 - ETA: 1:45 - loss: 1.0341 - sparse_categorical_accuracy: 0.634 - ETA: 1:45 - loss: 1.0345 - spar - ETA: 1:43 - loss: 1.0353 - sparse_categorica - ETA: 1:42 - loss: 1.0347 - sparse_categorical_accuracy: 0 - ETA: 1:42 - loss: 1.0347 - sparse_categorical_accura - ETA: 1:41 - loss: 1.0356 - sparse_categorical_ - E - ETA: 1:32 - loss: 1.0350 - sparse_categorical_accuracy: 0.634 - ETA: 1:32 - loss: 1.0351 - sparse_ca - ETA: 1:30 - loss: 1.0356 - sparse_cate - ETA: 1:28 - loss: 1.0370 - sparse_categorical_ - ETA: 1:27 - loss: 1.0379 - sparse_categorical_accuracy: 0.63 - ETA: 1:27 - loss: 1.0380 - sparse_categorical_accuracy: - ETA: 1:27 - loss: 1.0385  - ETA: 1:24 - loss: 1.0389 - sparse_categorical_accur - ETA: 1:24 - loss: 1.0391 - sparse_categorical_accuracy: 0.632 - ETA: 1:24 - loss: 1.0389 - sparse_categorical_accuracy: 0 - ETA: 1:23 - loss: 1.0396 - sparse_categorical_accuracy: 0.63 - ETA: 1:23 - loss: 1.0396 - sparse_categorical_ - ETA: 1:22 - loss: 1.0399 - sparse_categorical_accurac - ETA: 1:21 - loss: 1.0391 - sparse_categorical_accuracy: 0. - ETA: 1:21 - loss: 1.0388 - sparse_categorical_accuracy: - ETA: 1:21 - loss: 1.0392 - sparse_categorical_accuracy: 0.6 - ETA: 1 - ETA: 1:17 - loss: 1.0370 - sparse_categ - ETA: 1:15 - loss: - ETA: 1:13 - loss: 1.0359 - sparse_categorical_accuracy: 0 - ETA: 1:12 - loss: 1.0362 - sparse_categorical_accuracy:  - ETA: 1:12 - loss: 1.0362 - sparse_categorical_accuracy: - ETA: 1:11 - loss: 1.0364 - sparse_categori - ETA: 1:10 - loss: 1.0360 - sparse_categorical_accurac - ETA: 1:10 - loss: 1.0365 - sparse_categorical_accuracy: 0.63 - ETA: 1:09 - loss: 1.0363 - sparse_categor - ETA: 1:08 - loss: 1.0373 - sparse_categorical_accuracy: 0.633 - ETA: 1:08 - loss: 1.0375 - sparse_categorical_accuracy: 0. - ETA: 1:08 - loss: 1.0376 - sparse_categorical_accurac - ETA: 1:07 - loss:  - ETA: 1:04 -  - ETA: 1:01 - loss: 1.0396 - sparse_categorical_accuracy: 0.633 - ETA: 1:01 - loss: 1.0395 - sparse_cate - ETA: 1:00 - loss: 1.0400 - sparse_categor - ETA: 59s - loss: 1. - ETA: 57s - loss: 1.0415 - sparse_categorical_ac - ETA:  - ETA: 47s - loss: 1.0445 - sparse_categorica - ETA: 46s - loss: 1.0451 - sparse_categorical_accuracy:  - ETA: 46s - lo - ETA: 45s - loss: 1. - ETA: 41s - loss: 1.0453 - sparse_cate - ETA: 41s - loss: 1.0456 - sparse_ca - ETA: 40s - loss: 1.04 - ETA: 38s - loss: 1.04 - ETA: 37s - loss: 1.0458 - sparse_ca - ETA: 36s - loss: 1.0457 - sparse_categorical_accura - ETA: 36s - loss: 1.0457 - sparse_ - ETA: 35s - loss: 1.0464 - spars - ETA: 34s  - ETA: 30s - loss - ETA: 27s - loss: 1.0483 - sparse_categorical_accura - ETA: 27s - loss: 1.0488 - sparse_categorical_accuracy - ETA: 26s - loss: 1.0489 - ETA:  - ETA: 13s - loss: 1.0511 - sparse_categorical_accuracy - ETA: 8s - loss: 1.0522 - sparse_categorical_accuracy:  - ETA: 7s - loss: 1.0524 - sparse_categorical_accuracy: 0 - ETA: 7s - loss: 1.0527 - sparse_ca - ETA: 5s - loss: 1.0531 - sparse_categorical_accuracy: 0.627 - ETA: 5s - loss: 1.0529 - sparse_categorical_a - ETA: 4s - loss: 1.0533 - sparse_categorical_accuracy: - ETA: 4s - loss - ETA: 1s - loss: 1.0538 - sparse_categorical_accuracy: 0. - ETA: 1s - loss: 1.0538 - sparse_categorical_accuracy: 0.6 - ETA: 0s - loss: 1.0538 - sparse_categorical_accuracy: 0.6 - ETA: 0s - loss: 1.0540 - sparse_categorical_accur\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 217s 69ms/step - loss: 1.0136 - sparse_categorical_accuracy: 0.6435 - val_loss: 1.1302 - val_sparse_categorical_accuracy: 0.6099racy: 0.654 - ETA: 3:02 - loss: 0.9797 - sparse_categorical_accuracy:  - ETA: 3:01 - loss: 0.9802 - sparse_c - ETA: 2:59 - loss: 0.9824 - sparse_categorical_accuracy: 0. - ETA: 2:59 - loss: 0.9835 - spar - ETA: 2:57 - loss: 0.9815 - sparse_categoric - ETA: 2:56 - loss: 0.9778 - sparse_categorical_acc - ETA: 2:55 - loss: 0.9780 - sparse_categorical_accuracy: 0 - ETA: 2:54 - loss: 0.9777 - sparse_categorical_ - ETA: 2:53 - loss: 0.9799 - - ETA: 2:51 - loss: 0.9830 - sparse_categ - ETA: 2:49 - loss: 0.9827 - sparse_categorical_accuracy: 0.65 - ETA: 2:49 - loss: 0.9838 - sparse_c - ETA: 2:47 - loss: 0.9855 - sparse_catego - ETA: 2:45 - loss: 0.9832 - sparse_categorical_accuracy: 0 - ETA: 2:45 - loss: 0.9838  - ETA: 2:43 - loss: 0.9845 - sparse_categorical_accuracy: 0.651 - ETA: 2:43 - loss: 0.9846 - sparse_categorical_accuracy: 0.65 - ETA: 2:42 - loss: 0.9845 - sparse_categorical_accuracy:  - ETA: 2:42 - loss - ETA: 2:39 - loss: 0.9882 - spars - ETA: 2:32 - loss: 0.9892 - sparse_categorical_accuracy: 0 - ETA: 2:32 - loss: 0.9889 - sparse_categorical_accuracy:  - ETA: 2:32 - loss: 0.9887 - sparse_categorical_accuracy:  - ETA: 2:31 - loss: 0.9892 - sparse_categorical_accura - ETA: 2:31 - loss: 0.9892 - sparse_categorical_accura - ETA: 2:30 - loss: 0.9888 - sparse_categorical_accuracy: 0.65 - ETA: 2:30 - loss: 0.9901 - sparse_categorical_accuracy - ETA: 2:29 - loss: 0.9910 - spars - ETA: 2:27 - loss: 0.9897 - sparse_categorica - ETA: 2:26 - loss: 0.9911 - sparse_categorical_accuracy - ETA: 2:25 - loss: 0.9908 - sparse_categorical_accura - ETA: 2:25 - loss: 0.9920 - sparse_categ - ETA: 2:23 - loss: 0.9922 - spars - ETA: 2:21 - loss: 0.9927 - sparse_categor - ETA: 2:20 - loss: - ETA: 2:04 - loss: 0.9932 - sparse_categor - ETA: 2:02 - loss: 0.9948 - sparse_categorical_accuracy: 0. - ETA: 2:02 - loss: 0.9947 - sparse_categorical_ - ETA: 2:01 -  - ETA: 1:53 - loss: 0.9943 - sparse_catego - ETA: 1:52 - loss: 0.9941 - sparse_categorical_accuracy: 0. - ETA: 1:51 - loss: 0.9935 - sparse_ca - ETA: 1:50 - loss: 0.993 - ETA: 1:47 - loss: 0.9949 - sparse_cat - ETA: 1:46 - loss: 0.9 - ETA: 1:43 - loss: 0.9942 - sparse_categorical_accuracy: 0.65 - ETA: 1:43 - loss: 0.9944 - sparse_categorical_accuracy: 0. - ETA: 1:43 - loss: 0.9944 - sparse_categorical_accuracy: 0.650 - ETA: 1:42 - loss: 0.9947 - sparse_cat - ETA: 1:41 - loss: 0.9957 - sparse_categor - ETA: 1:39 - loss: 0.9951 - sparse_categorical_accuracy: 0.65 - ETA: 1:39 - loss: 0.9950 - sparse_categorical_ - ETA: 1:34 - loss: 0.9975 - sparse_categorical_accuracy: 0.6 - ETA: 1:34 - loss: 0.9979 - sparse_categorical_accuracy: 0.6 - ETA: 1:33 - loss: 0.9980 - sparse_categorical_accu - ETA: 1:28 - loss: 1.0013 - sparse_categorical_accuracy: - ETA: 1:28 - loss: 1.0020 - spars - ETA: 1:26 - loss: 1.0023 - sparse_cate - ETA: 1:24 - loss: 1.0020 - sparse_categorical_accuracy: 0. - ETA: 1:24 - loss: 1.0026 - sparse_cat - ETA: 1:23 - loss: 1.0027 - sparse_categorical_accuracy: 0.646 - ETA: 1:22 - loss: 1.0028 - sparse_categorical_accurac - ETA: 1:22 - loss: 1.0023 - sparse_categoric - ETA: 1:21 - loss: 1.0026 - sparse_categorical_accu - ETA: 1:20 - loss: 1.0036 - sparse_categorical_accuracy - ETA: 1:19 - loss: 1.0033 - sparse_categorical_accuracy: 0.646 - ETA: 1:19 - loss: 1 - ETA: 1:16 - loss: 1.0024 - sparse_categorical_ - ETA: 1:15 - loss: 1.0026 - sparse_categorical_accuracy - ETA: 1:15  - ETA: 1:12 - loss: 1.0053 - sparse_catego - ETA: 5s - loss: 1.0125 - s - ETA: 2s - loss: 1.0131 - sparse_categorical_accuracy: 0.6 - ETA: 2s - loss: \n",
      "Epoch 10/10\n",
      "3125/3125 [==============================] - 219s 70ms/step - loss: 0.9819 - sparse_categorical_accuracy: 0.6546 - val_loss: 1.1027 - val_sparse_categorical_accuracy: 0.6178A: 3:03 - ETA: 2:59 - loss: 0.9333 - sparse_categorical_ - ETA: 2:58 - loss: 0.9304 - sparse_categorical_accura - ETA: 2:58 - loss: 0.9280 - sparse_categorical_accura - ETA: 2:57 - loss: 0.9270 - sparse_categorical_ - ETA: 2:52 - loss: 0.9323 - spa - ETA: 2:42 - loss: 0.9520  - ETA: 2:40 -  - ETA: 2:36 - loss: 0.9534 - sparse_categorical_accuracy: - ETA: 2:36 - loss: 0.9528 - sparse_c - ETA: 2:30 - loss: 0 - ETA: 2:27 - loss: 0.9622 - sparse_categorical_accurac - ETA: 2:26 - loss: 0.9635 - sparse_categorical_accuracy:  - ETA: 2:26 - loss: 0.9630 - sparse_categorical - ETA: 2:25 - loss: 0.9600 - sparse_categorical_accuracy: 0.662 - ETA: 2:25 - loss: 0. - ETA: 2:22 - loss: 0.9588 - sparse_categorical_accuracy: 0.662 - ETA: 2:22 - - ETA: 2:19 - loss: 0.9601 - sparse_catego - ETA: 2:18 - loss: 0.96 - ETA: 2:11 - loss: 0.9603 - sparse_categorical - ETA: 2:11 - loss: 0. - ETA: 2:08 - loss: 0.9642 - sparse_categorical_accur - ETA: 2:07 - loss: 0.9644 - sparse_categorical_accur - ETA: 2:06 - loss: 0.9643 - sparse_categorical_acc - ETA: 2:06 - loss: 0.9643 - sparse_categorical - ETA: 2:05 - loss: 0.9648 - sparse_categorical_accur - ETA: 2:04 - loss: 0. - ETA: 2:01 - loss: 0.9672 - spa - ETA: 1:59 - loss: 0.9695 - sparse_categorical_accuracy: 0.66 - ETA: 1:59 - loss: 0.9697 - sparse_categorical_accurac - ETA: 1:59 - loss: 0.9700 - sparse_categorical_accuracy: 0.660 - ETA: 1:59 - loss: 0.9697 - sparse_categorical_accuracy: 0.66 - ETA: 1:58 - loss: 0.9699 - - ETA: 1:52 - loss - ETA: 1:49 - loss: 0.9722 - sparse_categorical_accur - ETA: 1:48 - loss: 0.9727 - sparse_categorical_accuracy: - ETA: 1:47 - loss: 0.9741 - sparse_categorical_accuracy - ETA: 1:47 - loss: 0.9743 - sparse_categ - ETA: 1:46 - loss: 0 - ETA: 1: - ETA: 1:39 - loss: 0.9754 - sparse_catego - ETA: 1:38 - loss: 0.9752 - sparse_categorical_accurac - ETA: 1:37 - loss: 0.9752 - sparse_categorical_accuracy: 0.65 - ETA: 1:37 - loss: 0.9750 - sparse_categorical_accuracy - ETA: 1:36 - loss: 0.9761 - sparse_categorical_accu - ETA: 1:36 - loss: 0.9753 - s - ETA: 1:33 - loss: 0.9744 - sparse_categorical_accur - ETA: 1:33 - lo - ETA: 1:30 - loss: 0.9726 - sparse_categorical_accuracy: 0.6 - ETA: 1:29 - loss: 0.9728 - sparse_categorical_a - ETA: 1:28 - loss: 0.9725 - sparse_categorica - ETA: 1:27 - loss: 0.9731 - sparse - ETA: 1:25 - loss: 0.9729 - sparse_categ - ETA: 1:24 - loss: 0.9734 - sparse_categ - ETA: 1:22 - loss: 0.9730 - sparse_categ - ETA: 1:21 - ETA: 1:17 - loss: 0.9716 - sparse_categor - ETA: 1:16 - loss: 0.9730 - sparse_categor - ETA: 1:15 - loss: 0.9722 - sparse_categorical_accuracy - ETA: 1: - ETA: 1:11 - loss: - ETA: 1:08 - loss: 0.9754 - sparse_categorica - ETA: 1:06 - loss: 0.9749 - sparse_categorical_ - ETA: 1:05 - loss: 0.9746 - spa - ETA: 55s - loss: 0.9765 - sparse_categorical_ - ETA: 55s - loss: 0.9768 - sparse_categorica - ETA: 54s - loss: 0.9775 - sparse_categorical_accuracy: 0.65 - ETA: 54s - loss: 0.9773 - sparse_categorica - ETA: 53s - loss: 0.9774 - sparse_categorical_accuracy - ETA: 53s - loss: 0.9774 - sparse_cate - ETA: 52s - lo - E - ETA: 15s - loss: 0.9803 - sparse_categorica - ETA: 11s - loss: 0.9802 - sparse_categorical_accura - ETA: 10s - loss: 0.9801 - sparse_categorical_accuracy: 0. - ETA: 10s - loss: 0. - ETA: 8s - loss: 0.9805 - spars - ETA: 6s - loss: 0.9813 - sparse_categorical_accuracy: 0. - ETA: 6s - loss: 0.9815 - sparse_categorical_a - ETA: 5s - loss: 0.9815 - spa - ETA: 3s - loss: 0.9815 - sparse_categorical_accuracy:  - ETA: 3s \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2322365bac0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train/255,y_train,batch_size=16,epochs=10,validation_data=(x_test/255, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22fddc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block (Block)                (16, 16, 16, 8)           262       \n",
      "_________________________________________________________________\n",
      "block_1 (Block)              (16, 8, 8, 16)            1000      \n",
      "_________________________________________________________________\n",
      "block_2 (Block)              (16, 4, 4, 32)            3824      \n",
      "_________________________________________________________________\n",
      "block_3 (Block)              (16, 2, 2, 64)            14944     \n",
      "_________________________________________________________________\n",
      "block_4 (Block)              (16, 1, 1, 128)           59072     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (16, 128)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (16, 64)                  8256      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (16, 32)                  2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (16, 16)                  528       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (16, 10)                  170       \n",
      "=================================================================\n",
      "Total params: 90,136\n",
      "Trainable params: 90,136\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
